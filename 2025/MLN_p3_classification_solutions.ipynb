{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMCKs7W/RdfCYHR0h6vJGLL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abelowska/mlNeuro/blob/main/2025/MLN_p3_classification_solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple P300 Speller - solutions\n",
        "\n",
        "Detect when participant see target, and when non-target stimuli using [BI2015a dataset](https://neurotechx.github.io/moabb/generated/moabb.datasets.BI2015a.html#moabb.datasets.BI2015a)."
      ],
      "metadata": {
        "id": "ODKcAdRpEeOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install moabb\n",
        "!pip install mne"
      ],
      "metadata": {
        "id": "XrOGdAUfEdad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, **restart your session** and then run next cells."
      ],
      "metadata": {
        "id": "JPxOyG6triQt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "vYXtlf47OZum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import moabb\n",
        "import mne\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from mne.decoding import LinearModel, Vectorizer, get_coef"
      ],
      "metadata": {
        "id": "Y6GhZk2DEwvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare data"
      ],
      "metadata": {
        "id": "2Y-wkDlIR_xP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Fetch data"
      ],
      "metadata": {
        "id": "G0UVYnuAOc53"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhmbjyhwEbWO"
      },
      "outputs": [],
      "source": [
        "# Get data fro one subject. It might take a while\n",
        "dataset = moabb.datasets.BI2015a()\n",
        "data = dataset.get_data(subjects=[2])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "S1brgoQYSKIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract `MNE` `Raw` from the downloaded data"
      ],
      "metadata": {
        "id": "bm7SpMaAQTL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subject = 2\n",
        "session = '0'\n",
        "run = '0'\n",
        "\n",
        "raw = data[subject][session][run]\n",
        "raw"
      ],
      "metadata": {
        "id": "I5ZSua96JWVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Simple Raw pre-processing"
      ],
      "metadata": {
        "id": "cLiNdL9bQrWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = raw.plot()\n",
        "fig = raw.compute_psd().plot()\n",
        "# 1. re-reference: to almost-mastoids\n",
        "raw.set_eeg_reference(ref_channels=['T7', 'T8'])\n",
        "\n",
        "# 2. band-pass filter\n",
        "raw_filtered = raw.copy().filter(\n",
        "    picks=['eeg'],\n",
        "    l_freq=.1,\n",
        "    h_freq=30.0,\n",
        "    n_jobs=10,\n",
        "    method='iir',\n",
        "    iir_params=None\n",
        "    )\n",
        "\n",
        "# 3. Notch filter\n",
        "power_freq = 50\n",
        "nyquist_freq = raw_filtered.info['sfreq'] / 2\n",
        "\n",
        "raw_filtered = raw_filtered.notch_filter(\n",
        "    picks=['eeg', 'eog'],\n",
        "    freqs=np.arange(power_freq, nyquist_freq, power_freq),\n",
        "    n_jobs=10,\n",
        ")\n",
        "\n",
        "fig = raw_filtered.plot()\n",
        "fig = raw_filtered.compute_psd().plot()"
      ],
      "metadata": {
        "id": "1r11HXbAJ4Kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Create segments around stimuli"
      ],
      "metadata": {
        "id": "rlzcoWiIRDf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fing events on the STIM channel\n",
        "events = mne.find_events(raw_filtered)\n",
        "\n",
        "# create events dict\n",
        "event_ids = {'Target': 2, 'Non-Target': 1}\n",
        "\n",
        "# create segments\n",
        "tmin = -0.2\n",
        "tmax = 0.6\n",
        "baseline = (-0.2,0)\n",
        "epochs = mne.Epochs(\n",
        "    raw_filtered,\n",
        "    events,\n",
        "    event_id=event_ids,\n",
        "    picks=\"eeg\",\n",
        "    tmin=tmin,\n",
        "    tmax=tmax,\n",
        "    baseline=baseline,\n",
        "    preload=True\n",
        ")\n",
        "\n",
        "epochs"
      ],
      "metadata": {
        "id": "rts1LLkPJ6ND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Look into EEG signal for target and non-target stimuli"
      ],
      "metadata": {
        "id": "BEeZPVJMRknz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create ERPs\n",
        "target_erp = epochs['Target'].average()\n",
        "nontarget_erp = epochs['Non-Target'].average()\n",
        "\n",
        "# compare target and non-target ERPs\n",
        "picks = ['Cz']\n",
        "\n",
        "fig = mne.viz.plot_compare_evokeds(\n",
        "    evokeds = {'target': target_erp, 'non-target': nontarget_erp},\n",
        "    picks=picks,\n",
        "    invert_y=True\n",
        ")"
      ],
      "metadata": {
        "id": "C20pRHVyLMXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ML model"
      ],
      "metadata": {
        "id": "2fIP4H5IR6PD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you can use your `epochs` to create a model"
      ],
      "metadata": {
        "id": "3TEmQfGASZSM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MODEL 1: Problem with imbalanced classes\n",
        "\n",
        "**Feature**: mean amplitude at Cz channel in time window 0.25 - 0.45s after stimuli presentation"
      ],
      "metadata": {
        "id": "g_5q5I_Fnj7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###### Creates data for fitting #######################\n",
        "tmin = 0.25\n",
        "tmax = 0.45\n",
        "epochs_data = epochs.get_data(picks='Cz', tmin=tmin, tmax=tmax) # get epochs data in desired time-window and at desired channel\n",
        "epochs_data = epochs_data.mean(axis=-1) # average signal within time-window to get mean amplitude\n",
        "\n",
        "X = epochs_data.reshape(epochs_data.shape[0], -1) # reshape to (n_samples, n_features)\n",
        "y = epochs.events[:,-1] - 1 # create labels: you can use events code for this!\n",
        "\n",
        "print(f\"Shape of X data: {X.shape}, shape of y data: {y.shape}\\n\")\n",
        "\n",
        "###### Fit the simplest classification model ##########\n",
        "clf = LogisticRegression(random_state=0).fit(X, y)\n",
        "y_predicted = clf.predict(X)\n",
        "\n",
        "###### Print classification results ##################\n",
        "print(classification_report(y_true=y, y_pred=y_predicted))"
      ],
      "metadata": {
        "id": "uwkLL_x9R6YC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see, that your model preedict always class 0. It is the majority class, and it's due to huge imbalance between the classes - **390:78**"
      ],
      "metadata": {
        "id": "wkWwD2QUp3Jh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MODEL 2: Balanced Classes but Still Performs Poorly\n",
        "**Feature**: mean amplitude at Cz channel in time window 0.25 - 0.45s after stimuli presentation"
      ],
      "metadata": {
        "id": "Ec73ezU0qGb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###### Creates data for fitting #######################\n",
        "tmin = 0.25\n",
        "tmax = 0.45\n",
        "epochs_data = epochs.get_data(picks='Cz', tmin=tmin, tmax=tmax) # get epochs data in desired time-window and at desired channel\n",
        "epochs_data = epochs_data.mean(axis=-1) # average signal within time-window to get mean amplitude\n",
        "\n",
        "X = epochs_data.reshape(epochs_data.shape[0], -1) # reshape to (n_samples, n_features)\n",
        "y = epochs.events[:,-1] - 1 # create labels: you can use events code for this!\n",
        "\n",
        "print(f\"Shape of X data: {X.shape}, shape of y data: {y.shape}\\n\")\n",
        "\n",
        "###### Balance classes #################################\n",
        "### You can implement class balancing manually‚Äîfor example, by iterating\n",
        "### simultaneously over X and y and appending observations of each class\n",
        "### to separate lists. Alternatively, you can use an off-the-shelf\n",
        "### implementation, like the one shown below:###########\n",
        "\n",
        "undersampler = RandomUnderSampler(random_state=42)\n",
        "X_resampled, y_resampled = undersampler.fit_resample(X, y)\n",
        "\n",
        "print(f\"After resampling:\\nShape of X data: {X_resampled.shape}, shape of y data: {y_resampled.shape}\\n\")\n",
        "\n",
        "###### Fit the simplest classification model ##########\n",
        "clf = LogisticRegression(random_state=0).fit(X_resampled, y_resampled)\n",
        "y_predicted = clf.predict(X_resampled)\n",
        "\n",
        "###### Print classification results ##################\n",
        "print(classification_report(y_true=y_resampled, y_pred=y_predicted))"
      ],
      "metadata": {
        "id": "Rc2B0gVWjFb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now it's working a bit better, but overall performance is still basically random."
      ],
      "metadata": {
        "id": "oe9dw6Dfrvpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MODEL 3: Balanced Classes with Standard Scaler\n",
        "**Feature**: mean amplitude at Cz channel in time window 0.25 - 0.45s after stimuli presentation, scaled"
      ],
      "metadata": {
        "id": "ZXO-yNKsr6Wv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###### Creates data for fitting #######################\n",
        "tmin = 0.25\n",
        "tmax = 0.45\n",
        "epochs_data = epochs.get_data(picks='Cz', tmin=tmin, tmax=tmax) # get epochs data in desired time-window and at desired channel\n",
        "epochs_data = epochs_data.mean(axis=-1) # average signal within time-window to get mean amplitude\n",
        "\n",
        "X = epochs_data.reshape(epochs_data.shape[0], -1) # reshape to (n_samples, n_features)\n",
        "y = epochs.events[:,-1] - 1 # create labels: you can use events code for this!\n",
        "\n",
        "print(f\"Shape of X data: {X.shape}, shape of y data: {y.shape}\\n\")\n",
        "\n",
        "###### Balance classes #################################\n",
        "### You can implement class balancing manually‚Äîfor example, by iterating\n",
        "### simultaneously over X and y and appending observations of each class\n",
        "### to separate lists. Alternatively, you can use an off-the-shelf\n",
        "### implementation, like the one shown below:###########\n",
        "\n",
        "undersampler = RandomUnderSampler(random_state=42)\n",
        "X_resampled, y_resampled = undersampler.fit_resample(X, y)\n",
        "\n",
        "print(f\"After resampling:\\nShape of X data: {X_resampled.shape}, shape of y data: {y_resampled.shape}\\n\")\n",
        "\n",
        "###### Fit the simplest classification model ##########\n",
        "##$ But now use Pipelines and Standard Scaler #########\n",
        "clf = make_pipeline(StandardScaler(), LogisticRegression(random_state=0)).fit(X_resampled, y_resampled)\n",
        "y_predicted = clf.predict(X_resampled)\n",
        "\n",
        "###### Print classification results ##################\n",
        "print(classification_report(y_true=y_resampled, y_pred=y_predicted))"
      ],
      "metadata": {
        "id": "x0OvtydJrvxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's a huge improvement! Now it's working much better, but the model is still biased toward the 0 class, and the recall for the 1 class is below chance level."
      ],
      "metadata": {
        "id": "L4040hh7sQvq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MODEL 4: Balanced Classes with Standard Scaler and more features\n",
        "**Feature**: amplitude at Cz channel in time window 0.25 - 0.45s after stimuli presentation, scaled\n",
        "\n",
        "**Note, that now we don't have mean amplitude (one feature), but the whole signal from the time-window (in this calse it is 102 features).**"
      ],
      "metadata": {
        "id": "DviA7LF2sngO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###### Creates data for fitting #######################\n",
        "tmin = 0.25\n",
        "tmax = 0.45\n",
        "picks=['Cz']\n",
        "epochs_data = epochs.get_data(picks=picks, tmin=tmin, tmax=tmax) # get epochs data in desired time-window and at desired channel\n",
        "\n",
        "X = epochs_data.reshape(epochs_data.shape[0], -1) # reshape to (n_samples, n_features)\n",
        "y = epochs.events[:,-1] - 1 # create labels: you can use events code for this!\n",
        "\n",
        "print(f\"Shape of X data: {X.shape}, shape of y data: {y.shape}\\n\")\n",
        "\n",
        "###### Balance classes #################################\n",
        "### You can implement class balancing manually‚Äîfor example, by iterating\n",
        "### simultaneously over X and y and appending observations of each class\n",
        "### to separate lists. Alternatively, you can use an off-the-shelf\n",
        "### implementation, like the one shown below:###########\n",
        "\n",
        "undersampler = RandomUnderSampler(random_state=42)\n",
        "X_resampled, y_resampled = undersampler.fit_resample(X, y)\n",
        "\n",
        "print(f\"After resampling:\\nShape of X data: {X_resampled.shape}, shape of y data: {y_resampled.shape}\\n\")\n",
        "\n",
        "###### Fit the simplest classification model ##########\n",
        "##$ But now use Pipelines and Standard Scaler #########\n",
        "clf = make_pipeline(StandardScaler(), LogisticRegression(random_state=0)).fit(X_resampled, y_resampled)\n",
        "y_predicted = clf.predict(X_resampled)\n",
        "\n",
        "###### Print classification results ##################\n",
        "print(classification_report(y_true=y_resampled, y_pred=y_predicted))"
      ],
      "metadata": {
        "id": "0vOHeqQyjFeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Looking into the model: visualization of model parameters (coefficients)"
      ],
      "metadata": {
        "id": "8i1Xn_82tFqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coefs = clf['logisticregression'].coef_.flatten() # assuming that model was a pipeline\n",
        "x_ticks = np.linspace(tmin, tmax, len(coefs))\n",
        "\n",
        "abs_max = np.max(np.abs(coefs))\n",
        "coefs_2d = coefs[np.newaxis, :]\n",
        "\n",
        "plt.figure(figsize=(10, 2))\n",
        "plt.imshow(\n",
        "    coefs_2d,\n",
        "    aspect='auto',\n",
        "    cmap='bwr',\n",
        "    interpolation='none',\n",
        "    extent=[tmin, tmax, 0, len(picks)],\n",
        "    vmin=-abs_max,\n",
        "    vmax=abs_max\n",
        "    )\n",
        "plt.colorbar(label=\"Coefficient Value\")\n",
        "plt.yticks(np.arange(len(picks)), labels=picks)\n",
        "plt.xlabel(\"Time\")\n",
        "plt.title(\"Classifier Coefficients Over Time\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NfnTWIUgmR5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MODEL 5: Balanced Classes with Standard Scaler and spatial features\n",
        "**Feature**: amplitude at Fz, C, and Pz channel in time window 0.25 - 0.45s after stimuli presentation, scaled"
      ],
      "metadata": {
        "id": "E6iEHXwru7jC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###### Creates data for fitting #######################\n",
        "tmin = 0.25\n",
        "tmax = 0.45\n",
        "picks = ['Cz', 'CP1', 'CP2', 'Pz']\n",
        "epochs_data = epochs.get_data(picks, tmin=tmin, tmax=tmax) # get epochs data in desired time-window and at desired channel\n",
        "\n",
        "X = epochs_data.reshape(epochs_data.shape[0], -1) # reshape to (n_samples, n_features)\n",
        "y = epochs.events[:,-1] - 1 # create labels: you can use events code for this!\n",
        "\n",
        "print(f\"Shape of X data: {X.shape}, shape of y data: {y.shape}\\n\")\n",
        "\n",
        "###### Balance classes #################################\n",
        "### You can implement class balancing manually‚Äîfor example, by iterating\n",
        "### simultaneously over X and y and appending observations of each class\n",
        "### to separate lists. Alternatively, you can use an off-the-shelf\n",
        "### implementation, like the one shown below:###########\n",
        "\n",
        "undersampler = RandomUnderSampler(random_state=42)\n",
        "X_resampled, y_resampled = undersampler.fit_resample(X, y)\n",
        "\n",
        "print(f\"After resampling:\\nShape of X data: {X_resampled.shape}, shape of y data: {y_resampled.shape}\\n\")\n",
        "\n",
        "###### Fit the simplest classification model ##########\n",
        "### But now use Pipelines and Standard Scaler #########\n",
        "clf = make_pipeline(StandardScaler(), LogisticRegression(random_state=0)).fit(X_resampled, y_resampled)\n",
        "y_predicted = clf.predict(X_resampled)\n",
        "\n",
        "###### Print classification results ##################\n",
        "print(classification_report(y_true=y_resampled, y_pred=y_predicted))"
      ],
      "metadata": {
        "id": "V4OJ1lI4u7sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Looking into the model: visualization of model parameters (coefficients)"
      ],
      "metadata": {
        "id": "2znTG3sxu70W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coefs = clf['logisticregression'].coef_.flatten()  # assuming that model was a pipeline\n",
        "coefs_2d = coefs.reshape(len(picks), -1)\n",
        "\n",
        "x_ticks = np.linspace(tmin, tmax, coefs_2d.shape[-1])\n",
        "\n",
        "abs_max = np.max(np.abs(coefs))\n",
        "\n",
        "plt.figure(figsize=(10, 2))\n",
        "plt.imshow(\n",
        "    coefs_2d,\n",
        "    aspect='auto',\n",
        "    cmap='bwr',\n",
        "    interpolation='none',\n",
        "    extent=[tmin, tmax, 0, len(picks)],  # Adjust the extent of y-axis to match number of picks\n",
        "    vmin=-abs_max,\n",
        "    vmax=abs_max\n",
        "    )\n",
        "plt.colorbar(label=\"Coefficient Value\")\n",
        "plt.yticks(np.arange(len(picks)), labels=picks)  # Set y-ticks with your channel names\n",
        "plt.xlabel(\"Time\")\n",
        "plt.title(\"Classifier Coefficients Over Time\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WpPjXsplu79k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test your model"
      ],
      "metadata": {
        "id": "u9KQTXjQSUc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_test_data(session='1'):\n",
        "  subject = 2\n",
        "  session = session\n",
        "  run = '0'\n",
        "\n",
        "  test_raw = data[subject][session][run]\n",
        "  # 1. re-reference: to almost-mastoids\n",
        "  test_raw.set_eeg_reference(ref_channels=['T7', 'T8'])\n",
        "\n",
        "  # 2. band-pass filter\n",
        "  test_raw_filtered = test_raw.copy().filter(\n",
        "      picks=['eeg'],\n",
        "      l_freq=.1,\n",
        "      h_freq=30.0,\n",
        "      n_jobs=10,\n",
        "      method='iir',\n",
        "      iir_params=None\n",
        "      )\n",
        "\n",
        "  # 3. Notch filter\n",
        "  power_freq = 50\n",
        "  nyquist_freq = test_raw_filtered.info['sfreq'] / 2\n",
        "\n",
        "  test_raw_filtered = test_raw_filtered.notch_filter(\n",
        "      picks=['eeg', 'eog'],\n",
        "      freqs=np.arange(power_freq, nyquist_freq, power_freq),\n",
        "      n_jobs=10,\n",
        "  )\n",
        "\n",
        "  # fing events on the STIM channel\n",
        "  events = mne.find_events(test_raw_filtered)\n",
        "\n",
        "  # create events dict\n",
        "  event_ids = {'Target': 2, 'Non-Target': 1}\n",
        "\n",
        "  # create segments\n",
        "  tmin = -0.2\n",
        "  tmax = 0.6\n",
        "  baseline = (-0.2,0)\n",
        "  test_epochs = mne.Epochs(\n",
        "      test_raw_filtered,\n",
        "      events,\n",
        "      event_id=event_ids,\n",
        "      tmin=tmin,\n",
        "      tmax=tmax,\n",
        "      baseline=baseline,\n",
        "  )\n",
        "\n",
        "  return test_epochs\n",
        "\n",
        "\n",
        "def test_checker(X_test, y_test, model, n_samples=10):\n",
        "  for i in range(len(X_test[:n_samples])):\n",
        "      print(f\"Checking test trial {i + 1}...\\n\")\n",
        "      time.sleep(1.4)\n",
        "\n",
        "      # Get the prediction for the current sample\n",
        "      y_pred = model.predict(X_test[i].reshape(1, -1))\n",
        "\n",
        "      # Check if the prediction is correct\n",
        "      if y_pred[0] == y_test[i]:\n",
        "          print(\"Correct! ‚ù§Ô∏è\\n\\n\")\n",
        "      else:\n",
        "          print(\"Incorrect! üò¢\\n\\n\")\n",
        "\n",
        "      time.sleep(0.5)\n",
        "  y_test_predicted = model.predict(X_test)\n",
        "  print(classification_report(y_test, y_test_predicted))"
      ],
      "metadata": {
        "id": "6dzvtTygSmXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_epochs = get_test_data(session='1')"
      ],
      "metadata": {
        "id": "2D2GIKuVSUmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transform your data in exaclty the same way as training data, to facilitate testing procedure:"
      ],
      "metadata": {
        "id": "2kyaAHg7ToO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###### Creates data for fitting #######################\n",
        "tmin = 0.25\n",
        "tmax = 0.45\n",
        "picks = ['Cz', 'CP1', 'CP2', 'Pz']\n",
        "epochs_data = test_epochs.get_data(picks, tmin=tmin, tmax=tmax) # get epochs data in desired time-window and at desired channel\n",
        "\n",
        "X_test = epochs_data.reshape(epochs_data.shape[0], -1) # reshape to (n_samples, n_features)\n",
        "y_test = test_epochs.events[:,-1] - 1 # create labels: you can use events code for this!\n",
        "\n",
        "print(f\"Shape of X data: {X_test.shape}, shape of y data: {y_test.shape}\\n\")\n",
        "\n",
        "###### Balance classes #################################\n",
        "### You can implement class balancing manually‚Äîfor example, by iterating\n",
        "### simultaneously over X and y and appending observations of each class\n",
        "### to separate lists. Alternatively, you can use an off-the-shelf\n",
        "### implementation, like the one shown below:###########\n",
        "\n",
        "undersampler = RandomUnderSampler(random_state=42)\n",
        "X_test_resampled, y_test_resampled = undersampler.fit_resample(X_test, y_test)\n",
        "\n",
        "print(f\"After resampling:\\nShape of X data: {X_test_resampled.shape}, shape of y data: {y_test_resampled.shape}\\n\")"
      ],
      "metadata": {
        "id": "35bJm7zBVPTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And run `test_checker()` !"
      ],
      "metadata": {
        "id": "MkfvPV9vYMkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_checker(X_test=X_test_resampled, y_test=y_test_resampled, model=clf)"
      ],
      "metadata": {
        "id": "AZ83BKXgTSyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8f5siiZz0Jrv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}