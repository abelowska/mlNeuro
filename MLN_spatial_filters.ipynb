{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMl4ctfCe6SKcjApToZkk/6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abelowska/mlNeuro/blob/main/MLN_spatial_filters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spatial filters\n",
        "\n",
        "See the MNE wonderful tutorials and documantation to better understand spatial filters: [https://mne.tools/stable/auto_tutorials/machine-learning/50_decoding.html#spatial-filters](https://mne.tools/stable/auto_tutorials/machine-learning/50_decoding.html#spatial-filters)\n"
      ],
      "metadata": {
        "id": "7Et0uoaM6IZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mne"
      ],
      "metadata": {
        "id": "lrBNP7oQ5Irj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "7MTF2UKl6IbW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ce9bBEd04ulQ"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import mne\n",
        "from mne.datasets import eegbci\n",
        "from mne.datasets import sample\n",
        "from mne.decoding import UnsupervisedSpatialFilter, CSP, Vectorizer\n",
        "\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, classification_report\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SequentialFeatureSelector\n",
        "from sklearn.decomposition import PCA, FastICA"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read data"
      ],
      "metadata": {
        "id": "ifRuaAV27zX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = Path('./data')\n",
        "epochs_subjects = []\n",
        "\n",
        "for idx in np.arange(1,11):\n",
        "  fname = data_dir / f'subj_{idx}-epo.fif'\n",
        "  print(fname)\n",
        "  epochs = mne.read_epochs(fname)\n",
        "  epochs_subjects.append(epochs)"
      ],
      "metadata": {
        "id": "WdFVY1wzXABj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize data"
      ],
      "metadata": {
        "id": "3990m4viXzOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_epochs = mne.concatenate_epochs(epochs_subjects)"
      ],
      "metadata": {
        "id": "eMBe_HQfYB3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Joint plot per condition"
      ],
      "metadata": {
        "id": "Ndq1DwonZ_3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = all_epochs['left'].average().plot_joint(times=[-1, 0.5, 0.8, 1.5, 2,3,4])\n",
        "fig = all_epochs['right'].average().plot_joint(times=[-1, 0.5, 0.8, 1.5, 2,3,4])"
      ],
      "metadata": {
        "id": "9h6jizLUYMbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Single-channel plots"
      ],
      "metadata": {
        "id": "SJRSZkMVaUQW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "picks = ['C3', 'Cz', 'C4']\n",
        "\n",
        "evokeds = dict(\n",
        "    left=list(all_epochs[\"left\"].iter_evoked()),\n",
        "    right=list(all_epochs[\"right\"].iter_evoked()),\n",
        ")\n",
        "\n",
        "for idx, pick in enumerate(picks):\n",
        "  plt.figure(idx)\n",
        "  fig = mne.viz.plot_compare_evokeds(evokeds, picks=pick)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "c2_5P4cwX3Cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spatial filters"
      ],
      "metadata": {
        "id": "DDjOoKafl6Zt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PCA"
      ],
      "metadata": {
        "id": "w1u8poRRmCxT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Fit PCA to all data"
      ],
      "metadata": {
        "id": "u88C-WQOm-bc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define PCA\n",
        "n_components = 2\n",
        "pca = UnsupervisedSpatialFilter(PCA(n_components), average=False)\n",
        "\n",
        "# get data to train PCA\n",
        "X = all_epochs.get_data(copy=False)\n",
        "\n",
        "# fit PCA\n",
        "pca.fit(X)\n",
        "\n",
        "# extract sklearn PCA object\n",
        "pca_estimator = pca.estimator"
      ],
      "metadata": {
        "id": "vFdlHLJYmcER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Explore PCA\n",
        "\n",
        "Note, that PCA components has shape of *(n_components, n_channels)*, as each channel is a sample for PCA."
      ],
      "metadata": {
        "id": "Zsqs3X1Jokmk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# explained variance of X\n",
        "print(pca_estimator.explained_variance_ratio_)\n",
        "\n",
        "# shape of PCA components\n",
        "print(pca_estimator.components_.shape)"
      ],
      "metadata": {
        "id": "t8R-XJs4oR3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can use mne tool for vizualization to see the PCA weights that were estimated for each channel, i.e., patterns. They show how each channel contribute to the given PCA component."
      ],
      "metadata": {
        "id": "AmomV-hvqi11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in np.arange(0, n_components):\n",
        "  # create canvas\n",
        "  plt.figure(i)\n",
        "\n",
        "  # get data of i-th component\n",
        "  spatial_data = pca_estimator.components_[i]\n",
        "  mne.viz.plot_topomap(\n",
        "      spatial_data,\n",
        "      pos=all_epochs.info,\n",
        "      show=False\n",
        "  )\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "ddNUPRfRp0MU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Transform data using fitted PCA"
      ],
      "metadata": {
        "id": "KFIzno61sZGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_filtered = pca.transform(X)\n",
        "\n",
        "print(f'X shape befor PCA: {X.shape}\\nX shape after PCA: {X_filtered.shape}')"
      ],
      "metadata": {
        "id": "UrqdX6COssQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can compare the waves of single-channel X with the pattern of the first (main) PCA component"
      ],
      "metadata": {
        "id": "UhmCJoeZpeBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot evoke for selected channels from X\n",
        "c3_index = all_epochs.info.ch_names.index('C3')\n",
        "fz_index = all_epochs.info.ch_names.index('Fz')\n",
        "\n",
        "X_mean = np.mean(X, axis=0)\n",
        "plt.plot(X_mean[c3_index])\n",
        "plt.plot(X_mean[fz_index])\n",
        "\n",
        "\n",
        "# plot evoke for the first component from X_filtered\n",
        "pca_component_index = 0\n",
        "X_filtered_mean = np.mean(X_filtered, axis=0)\n",
        "plt.plot(X_filtered_mean[pca_component_index])"
      ],
      "metadata": {
        "id": "m9r2fHFJpeKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The easiest way to check if PCA captured the difference between the conditions, and thus is suitable for our analysis, is to wrap data transformed with PCA to `Epochs` object that store info on events."
      ],
      "metadata": {
        "id": "somPo9iSwjQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# original data\n",
        "print(all_epochs)\n",
        "\n",
        "# create info for transformed data\n",
        "events = all_epochs.events\n",
        "\n",
        "info = mne.create_info(\n",
        "    n_components,\n",
        "    epochs.info['sfreq'],\n",
        "    ch_types='eeg'\n",
        ")\n",
        "\n",
        "all_epochs_pca = mne.EpochsArray(\n",
        "    X_filtered,\n",
        "    info,\n",
        "    events,\n",
        "    tmin=all_epochs.tmin\n",
        ")\n",
        "print(all_epochs_pca)"
      ],
      "metadata": {
        "id": "qzVrHiFCwjYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can use all MNE methods for all_epochs_pca visualization."
      ],
      "metadata": {
        "id": "keWSl_MIzlYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# original data\n",
        "picks = ['C3']\n",
        "\n",
        "evokeds = dict(\n",
        "    left=list(all_epochs[\"left\"].iter_evoked()),\n",
        "    right=list(all_epochs[\"right\"].iter_evoked()),\n",
        ")\n",
        "\n",
        "fig = mne.viz.plot_compare_evokeds(evokeds, picks=picks)"
      ],
      "metadata": {
        "id": "xEbeIWvHymPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA filtered data\n",
        "picks = ['0']\n",
        "\n",
        "evokeds_pca = dict(\n",
        "    left=list(all_epochs_pca[\"1\"].iter_evoked()),\n",
        "    right=list(all_epochs_pca[\"2\"].iter_evoked()),\n",
        ")\n",
        "\n",
        "fig = mne.viz.plot_compare_evokeds(evokeds_pca, picks=picks)"
      ],
      "metadata": {
        "id": "fO87wDZDyzY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCA does not seem to be the best approach we can adopt ;)"
      ],
      "metadata": {
        "id": "nB68fSRR0FZy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CSP"
      ],
      "metadata": {
        "id": "81HSPkhImcOQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Fit CSP to all data\n",
        "\n",
        "Note that because CSP is a supervised method, we have to provide the *y* set to CSP."
      ],
      "metadata": {
        "id": "yVELQc2C0Wut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define PCA\n",
        "n_components = 2\n",
        "csp = CSP(n_components)\n",
        "\n",
        "# get data to train CSP\n",
        "X = all_epochs.get_data(copy=False)\n",
        "y = all_epochs.events[:, -1] - 1\n",
        "\n",
        "# fit CSP\n",
        "csp.fit(X, y)"
      ],
      "metadata": {
        "id": "m6Viz9AA0Wut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Explore CSP\n",
        "\n",
        "Using build-in functions we can easily plot patterns (CSP weights; also called mixing matrix) and filters (CSP weights/patterns multiplied by the original data)."
      ],
      "metadata": {
        "id": "-iLuKokp0Wut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = csp.plot_patterns(all_epochs.info)"
      ],
      "metadata": {
        "id": "NfxKiZzx2-1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = csp.plot_filters(all_epochs.info)"
      ],
      "metadata": {
        "id": "_tZ1xzd01Vs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note, that the forst CSP pattern is quite similar to our forst PCA component/pattern that captures most of the variance in X!"
      ],
      "metadata": {
        "id": "KCuSPiDy3Cnb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Transform the original data"
      ],
      "metadata": {
        "id": "Bajc03e49vte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_filtered_csp = csp.transform(X)\n",
        "\n",
        "print(f'X shape befor PCA: {X.shape}\\nX shape after PCA: {X_filtered_csp.shape}')"
      ],
      "metadata": {
        "id": "5xFuFIwLvfKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CSP does not preserve the time dimension; it averages the signal along the time domain. As a result of CSP, we obtain as many features as the number of CSP components we declare."
      ],
      "metadata": {
        "id": "K6T0k8FG-Ad1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification"
      ],
      "metadata": {
        "id": "HgQ5vxTfegtm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def estimate_model(\n",
        "    X_train,\n",
        "    X_test,\n",
        "    y_train,\n",
        "    y_test,\n",
        "    model=SVC()\n",
        "):\n",
        "  # fit\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  # predict test and train data\n",
        "  y_test_predicted = model.predict(X_test)\n",
        "  y_train_predicted = model.predict(X_train)\n",
        "\n",
        "  print(f'Classification report for testing data:\\n{classification_report(y_test, y_test_predicted)}')\n",
        "  print(f'Classification report for training data:\\n{classification_report(y_train, y_train_predicted)}')\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "Vs9WdenJXpN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create train and test sets"
      ],
      "metadata": {
        "id": "PbcVhcW9-71K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split_epochs(epochs_list, split=0.7):\n",
        "  train_n = int(len(epochs_list)*split)\n",
        "  test_n = len(epochs_list) - train_n\n",
        "  train_epochs = mne.concatenate_epochs(epochs_list[:train_n])\n",
        "  test_epochs = mne.concatenate_epochs(epochs_list[-test_n:])\n",
        "\n",
        "  X_train = train_epochs.get_data(copy=True)\n",
        "  X_test = test_epochs.get_data(copy=True)\n",
        "  y_train = train_epochs.events[:, -1] - 1\n",
        "  y_test = test_epochs.events[:, -1] - 1\n",
        "\n",
        "  return X_train, y_train, X_test, y_test"
      ],
      "metadata": {
        "id": "XxnkQ8Lp-tf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. PCA-based features\n"
      ],
      "metadata": {
        "id": "0lLjTzI9XXjG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Just pipe all transformed data to the model. Note that `UnsupervisedSpatialFilter` object is a transformer, so we can use it within `pipelines`. This helps prevent knowledge leakage from the training set to the test set when performing PCA."
      ],
      "metadata": {
        "id": "Jtq8RpCZZCMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define X and y sets\n",
        "X_train, y_train, X_test, y_test = train_test_split_epochs(\n",
        "    epochs_subjects,\n",
        "    split=0.7\n",
        ")\n",
        "\n",
        "print(X_train.shape)"
      ],
      "metadata": {
        "id": "yWEEX-sleh1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_components = 2\n",
        "\n",
        "model = make_pipeline(\n",
        "    UnsupervisedSpatialFilter(PCA(n_components), average=False),\n",
        "    Vectorizer(),  # vectorize across time and channels to n_samples, n_features\n",
        "    StandardScaler(),\n",
        "    SVC(),\n",
        ")\n",
        "\n",
        "_ = estimate_model(\n",
        "    X_train,\n",
        "    X_test,\n",
        "    y_train,\n",
        "    y_test,\n",
        "    model=model\n",
        ")"
      ],
      "metadata": {
        "id": "p69ZfYACH3qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Exercise\n",
        "2. Extract the mean amplitude within a selected time-window from the first PCA component. Note that in the previous example, we performed **all data transformations within pipelines**. Now, you have the option to write your own transformer to extract the mean amplitude from each 'channel' (e.g., https://medium.com/@pgshanding/creating-custom-transformers-in-python-and-scikit-learn-10767487017e) or perform PCA outside of the pipelines."
      ],
      "metadata": {
        "id": "CVUN0wWpaLuv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define X and y sets\n",
        "X_train, y_train, X_test, y_test = train_test_split_epochs(\n",
        "    epochs_subjects,\n",
        "    split=0.7\n",
        ")"
      ],
      "metadata": {
        "id": "CB0H_E_HwAlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "\n",
        "model = make_pipeline()\n",
        "\n",
        "_ = estimate_model(\n",
        "    X_train,\n",
        "    X_test,\n",
        "    y_train,\n",
        "    y_test,\n",
        "    model=model\n",
        ")"
      ],
      "metadata": {
        "id": "GDp32d5VaLuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CSP-based features"
      ],
      "metadata": {
        "id": "Fulc4ChhERKO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exercise\n",
        "\n",
        "Try to use CSP to extract *n* features from our data. Did CSP significantly improve the classification results? To avoid choosing n manually, you can use  [`GridSearch`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) to find the optimal *n* value."
      ],
      "metadata": {
        "id": "DdYD0EqC-Hp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define X and y sets\n",
        "X_train, y_train, X_test, y_test = train_test_split_epochs(\n",
        "    epochs_subjects,\n",
        "    split=0.7\n",
        ")"
      ],
      "metadata": {
        "id": "2FA_jcXZERTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "\n",
        "# model = TODO\n",
        "\n",
        "_ = estimate_model(\n",
        "    X_train,\n",
        "    X_test,\n",
        "    y_train,\n",
        "    y_test,\n",
        "    model=model\n",
        ")"
      ],
      "metadata": {
        "id": "7Z4afD_JEfT2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}