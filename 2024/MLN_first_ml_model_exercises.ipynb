{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNsAli1c+FOVcVtKAGVwMVX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abelowska/mlNeuro/blob/main/MLN_first_ml_model_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BCI classification model\n",
        "\n",
        "We are going to use the open [EEG Motor Movement/Imagery Dataset](https://physionet.org/content/eegmmidb/1.0.0/S001/#files-panel) to classify **imagining the opening and closing of left or right fists**.\n",
        "\n",
        "You can download the .zip file containing the already prepared `Epochs` of the first 10 participants here: . Each `Epochs` file consists of two types of events: *left* and *right*."
      ],
      "metadata": {
        "id": "7Et0uoaM6IZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mne"
      ],
      "metadata": {
        "id": "lrBNP7oQ5Irj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "7MTF2UKl6IbW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ce9bBEd04ulQ"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import mne\n",
        "from mne.datasets import eegbci\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, classification_report\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SequentialFeatureSelector\n",
        "from sklearn.feature_selection import SelectPercentile"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read data"
      ],
      "metadata": {
        "id": "ifRuaAV27zX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = Path('./data')\n",
        "epochs_subjects = []\n",
        "\n",
        "for idx in np.arange(1,11):\n",
        "  fname = data_dir / f'subj_{idx}-epo.fif'\n",
        "  print(fname)\n",
        "  epochs = mne.read_epochs(fname)\n",
        "  epochs_subjects.append(epochs)"
      ],
      "metadata": {
        "id": "WdFVY1wzXABj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize data"
      ],
      "metadata": {
        "id": "3990m4viXzOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_epochs = mne.concatenate_epochs(epochs_subjects)"
      ],
      "metadata": {
        "id": "eMBe_HQfYB3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Joint plot per condition"
      ],
      "metadata": {
        "id": "Ndq1DwonZ_3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = all_epochs['left'].average().plot_joint(times=[-1, 0.5, 0.8, 1.5, 2,3,4])\n",
        "fig = all_epochs['right'].average().plot_joint(times=[-1, 0.5, 0.8, 1.5, 2,3,4])"
      ],
      "metadata": {
        "id": "9h6jizLUYMbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Single-channel plots"
      ],
      "metadata": {
        "id": "SJRSZkMVaUQW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "picks = ['C3', 'Cz', 'C4']\n",
        "\n",
        "evokeds = dict(\n",
        "    left=list(all_epochs[\"left\"].iter_evoked()),\n",
        "    right=list(all_epochs[\"right\"].iter_evoked()),\n",
        ")\n",
        "\n",
        "for idx, pick in enumerate(picks):\n",
        "  plt.figure(idx)\n",
        "  fig = mne.viz.plot_compare_evokeds(evokeds, picks=pick)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "c2_5P4cwX3Cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Compare spectral representation (PSD) of conditions:"
      ],
      "metadata": {
        "id": "2z8pzsr2bGJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fmin = 1\n",
        "fmax = 30\n",
        "\n",
        "spectrum_left = all_epochs[\"left\"].compute_psd(fmin=fmin, fmax=fmax)\n",
        "spectrum_right = all_epochs[\"right\"].compute_psd(fmin=fmin, fmax=fmax)"
      ],
      "metadata": {
        "id": "ECrCqvR9c1SP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = spectrum_left.plot(picks=\"eeg\", exclude=\"bads\")\n",
        "fig = spectrum_right.plot(picks=\"eeg\", exclude=\"bads\")"
      ],
      "metadata": {
        "id": "IuvIOkiJX3FF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bands = {\n",
        "    'Delta (0-4 Hz)': (0, 4),\n",
        "    'Theta (4-8 Hz)': (4, 8),\n",
        "    'Alpha (8-12 Hz)': (8, 12),\n",
        "    'Beta (12-30 Hz)': (12, 30)\n",
        "}\n",
        "\n",
        "fig = spectrum_left.plot_topomap(bands=bands, normalize=True)\n",
        "fig = spectrum_right.plot_topomap(bands=bands, normalize=True)"
      ],
      "metadata": {
        "id": "izXD6nezcC3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification"
      ],
      "metadata": {
        "id": "HgQ5vxTfegtm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def estimate_model(\n",
        "    X_train,\n",
        "    X_test,\n",
        "    y_train,\n",
        "    y_test,\n",
        "    model=SVC()\n",
        "):\n",
        "  # fit\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  # predict test and train data\n",
        "  y_test_predicted = model.predict(X_test)\n",
        "  y_train_predicted = model.predict(X_train)\n",
        "\n",
        "  print(f'Classification report for testing data:\\n{classification_report(y_test, y_test_predicted)}')\n",
        "  print(f'Classification report for training data:\\n{classification_report(y_train, y_train_predicted)}')\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "Vs9WdenJXpN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Knowledge-based interpretable features\n"
      ],
      "metadata": {
        "id": "0lLjTzI9XXjG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.1 Time domain features"
      ],
      "metadata": {
        "id": "BpH2JpmAXl4R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- just pipe all data to the model"
      ],
      "metadata": {
        "id": "Jtq8RpCZZCMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create X and y datasets\n",
        "epochs = all_epochs.copy()\n",
        "\n",
        "y = epochs.events[:, -1] - 1\n",
        "X_data = epochs.get_data(copy=True)\n",
        "\n",
        "# reshape X to (n_samples, n_features) shape\n",
        "X = X_data.reshape(len(epochs), -1)\n",
        "\n",
        "print(f\"Shape of y set (labels): {y.shape}\\nShape of X set (features): {X.shape}\")"
      ],
      "metadata": {
        "id": "yWEEX-sleh1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit and predict\n",
        "X_train = X[:-135]\n",
        "X_test = X[-135:]\n",
        "y_train = y[:-135]\n",
        "y_test = y[-135:]\n",
        "\n",
        "_ = estimate_model(\n",
        "    X_train,\n",
        "    X_test,\n",
        "    y_train,\n",
        "    y_test,\n",
        ")"
      ],
      "metadata": {
        "id": "p69ZfYACH3qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- extract the mean amplitude in 0 - 1 s time-window from the C3 channel. This approach is knowledge-based, as it relies on the knowledge gained after visualizing the evoked potentials."
      ],
      "metadata": {
        "id": "CVUN0wWpaLuv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create X and y datasets\n",
        "epochs = all_epochs.copy()\n",
        "\n",
        "y = epochs.events[:, -1] - 1\n",
        "\n",
        "# extract data with get_data() and calculate mean along correct axis\n",
        "X = #\n",
        "\n",
        "# reshape X to (n_samples, n_features) shape\n",
        "X = X.reshape(len(epochs), -1)\n",
        "\n",
        "print(f\"Shape of y set (labels): {y.shape}\\nShape of X set (features): {X.shape}\")"
      ],
      "metadata": {
        "id": "GDp32d5VaLuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit and predict\n",
        "X_train = X[:-135]\n",
        "X_test = X[-135:]\n",
        "y_train = y[:-135]\n",
        "y_test = y[-135:]\n",
        "\n",
        "_ = estimate_model(\n",
        "    X_train,\n",
        "    X_test,\n",
        "    y_train,\n",
        "    y_test,\n",
        ")"
      ],
      "metadata": {
        "id": "lPKSN8u8aLuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- extract mean amplitude in 0 - 1 time window on FC3, FCz, FC4, C3, Cz, and C4 channels"
      ],
      "metadata": {
        "id": "7Rt8k5F_ajri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create X and y datasets\n",
        "epochs = all_epochs.copy()\n",
        "\n",
        "y = epochs.events[:, -1] - 1\n",
        "\n",
        "picks = ['FC3', 'FCz', 'FC4','C3', 'Cz', 'C4']\n",
        "X = # your code here\n",
        "\n",
        "# reshape X to (n_samples, n_features) shape\n",
        "X = X.reshape(len(epochs), -1)\n",
        "\n",
        "print(f\"Shape of y set (labels): {y.shape}\\nShape of X set (features): {X.shape}\")"
      ],
      "metadata": {
        "id": "L2yyZAR-ajrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit and predict\n",
        "X_train = X[:-135]\n",
        "X_test = X[-135:]\n",
        "y_train = y[:-135]\n",
        "y_test = y[-135:]\n",
        "\n",
        "_ = estimate_model(\n",
        "    X_train,\n",
        "    X_test,\n",
        "    y_train,\n",
        "    y_test,\n",
        ")"
      ],
      "metadata": {
        "id": "fkUdp8slajrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2 Frequency domain features"
      ],
      "metadata": {
        "id": "0QldWpi-fmHO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- just pipe all data to the model"
      ],
      "metadata": {
        "id": "dXoY7Z8yfmHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create X and y datasets\n",
        "epochs = all_epochs.copy()\n",
        "\n",
        "y = epochs.events[:, -1] - 1\n",
        "X_data = epochs.compute_psd().get_data()\n",
        "\n",
        "# reshape X to (n_samples, n_features) shape\n",
        "X = X_data.reshape(len(epochs), -1)\n",
        "\n",
        "print(f\"Shape of y set (labels): {y.shape}\\nShape of X set (features): {X.shape}\")"
      ],
      "metadata": {
        "id": "Zca9lAsRfmHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit and predict\n",
        "X_train = X[:-135]\n",
        "X_test = X[-135:]\n",
        "y_train = y[:-135]\n",
        "y_test = y[-135:]\n",
        "\n",
        "_ = estimate_model(\n",
        "    X_train,\n",
        "    X_test,\n",
        "    y_train,\n",
        "    y_test,\n",
        ")"
      ],
      "metadata": {
        "id": "gEAfT8s2fmHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- extract the mean power of alpha from the C3 channel **from time window of 0 - 1 s**. Mind that you have to crop your data and only then run `compute_pds()` method."
      ],
      "metadata": {
        "id": "jdrgkpmgfmHP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create X and y datasets\n",
        "epochs = all_epochs.copy()\n",
        "\n",
        "y = epochs.events[:, -1] - 1\n",
        "\n",
        "# crop data from 0 to 1 s\n",
        "cropped_epochs = # your code here\n",
        "\n",
        "# perform FFT decomposition\n",
        "spectrum_epochs = # your code here\n",
        "\n",
        "# extract features: average frequencies from alpha band\n",
        "X = # your code here\n",
        "\n",
        "# reshape X to (n_samples, n_features) shape\n",
        "X = X.reshape(len(epochs), -1)\n",
        "\n",
        "print(f\"Shape of y set (labels): {y.shape}\\nShape of X set (features): {X.shape}\")"
      ],
      "metadata": {
        "id": "7jo0vi_zfmHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit and predict\n",
        "X_train = X[:-135]\n",
        "X_test = X[-135:]\n",
        "y_train = y[:-135]\n",
        "y_test = y[-135:]\n",
        "\n",
        "_ = estimate_model(\n",
        "    X_train,\n",
        "    X_test,\n",
        "    y_train,\n",
        "    y_test,\n",
        ")"
      ],
      "metadata": {
        "id": "qYEWeICcfmHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- extract the mean power of alpha from the FC3, FCz, FC4, C3, Cz, and C4 channels from time window of 0 - 1 s."
      ],
      "metadata": {
        "id": "eUAt4l_JfmHP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create X and y datasets\n",
        "epochs = all_epochs.copy()\n",
        "\n",
        "y = epochs.events[:, -1] - 1\n",
        "\n",
        "# create X and y datasets\n",
        "epochs = all_epochs.copy()\n",
        "\n",
        "y = epochs.events[:, -1] - 1\n",
        "\n",
        "picks = ['FC3', 'FCz', 'FC4','C3', 'Cz', 'C4']\n",
        "\n",
        "# your code here\n",
        "# X =\n",
        "\n",
        "# reshape X to (n_samples, n_features) shape\n",
        "X = X.reshape(len(epochs), -1)\n",
        "\n",
        "print(f\"Shape of y set (labels): {y.shape}\\nShape of X set (features): {X.shape}\")"
      ],
      "metadata": {
        "id": "Ox4BN2TUfmHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit and predict\n",
        "X_train = X[:-135]\n",
        "X_test = X[-135:]\n",
        "y_train = y[:-135]\n",
        "y_test = y[-135:]\n",
        "\n",
        "_ = estimate_model(\n",
        "    X_train,\n",
        "    X_test,\n",
        "    y_train,\n",
        "    y_test,\n",
        ")"
      ],
      "metadata": {
        "id": "nA8nViyhfmHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.3 Combined time and frequency domain features"
      ],
      "metadata": {
        "id": "Nzlolr3jhT8f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- extract the mean power of alpha from the FC3, FCz, FC4, C3, Cz, and C4 channels from time window of 0 - 1 s.\n",
        "- extract the mean amplitude in time window 0 - 1 s from the FC3, FCz, FC4, C3, Cz, and C4 channels."
      ],
      "metadata": {
        "id": "XAQIGi0nhT8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "picks = ['FC3', 'FCz', 'FC4','C3', 'Cz', 'C4']\n",
        "\n",
        "# create X and y datasets\n",
        "epochs = all_epochs.copy()\n",
        "\n",
        "y = epochs.events[:, -1] - 1\n",
        "\n",
        "# create X and y datasets\n",
        "epochs = all_epochs.copy()\n",
        "\n",
        "y = epochs.events[:, -1] - 1\n",
        "\n",
        "# specral features\n",
        "# your code here\n",
        "# X_spectrum =\n",
        "\n",
        "# time-domain features\n",
        "# your code here\n",
        "# X_time =\n",
        "\n",
        "# concatenate features and reshape X to (n_samples, n_features) shape\n",
        "# use np.concatenate()\n",
        "# X =\n",
        "\n",
        "print(f\"Shape of y set (labels): {y.shape}\\nShape of X set (features): {X.shape}\")"
      ],
      "metadata": {
        "id": "hGWxugRVhT8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit and predict\n",
        "X_train = X[:-135]\n",
        "X_test = X[-135:]\n",
        "y_train = y[:-135]\n",
        "y_test = y[-135:]\n",
        "\n",
        "_ = estimate_model(\n",
        "    X_train,\n",
        "    X_test,\n",
        "    y_train,\n",
        "    y_test,\n",
        ")"
      ],
      "metadata": {
        "id": "4JQ9R41-hT8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.4 Combined time and frequency domain features and feature selection"
      ],
      "metadata": {
        "id": "AUt6rKo2iQVD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- extract the mean power of alpha from the FC3, FCz, FC4, C3, Cz, and C4 channels from time window of 0 - 1 s.\n",
        "- extract the mean amplitude in time window 0 - 1 s from the FC3, FCz, FC4, C3, Cz, and C4 channels.\n",
        "- select K=1 best features"
      ],
      "metadata": {
        "id": "SH-xsyA5iQVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "picks = ['FC3', 'FCz', 'FC4','C3', 'Cz', 'C4']\n",
        "\n",
        "# create X and y datasets\n",
        "epochs = all_epochs.copy()\n",
        "\n",
        "y = epochs.events[:, -1] - 1\n",
        "\n",
        "# create X and y datasets\n",
        "epochs = all_epochs.copy()\n",
        "\n",
        "y = epochs.events[:, -1] - 1\n",
        "\n",
        "# specral features\n",
        "# your code here\n",
        "# X_spectrum =\n",
        "\n",
        "# time-domain features\n",
        "# your code here\n",
        "# X_time =\n",
        "\n",
        "# concatenate features and reshape X to (n_samples, n_features) shape\n",
        "# use np.concatenate()\n",
        "# X =\n",
        "\n",
        "print(f\"Shape of y set (labels): {y.shape}\\nShape of X set (features): {X.shape}\")"
      ],
      "metadata": {
        "id": "-RaLGXkNiQVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit and predict\n",
        "X_train = X[:-135]\n",
        "X_test = X[-135:]\n",
        "y_train = y[:-135]\n",
        "y_test = y[-135:]\n",
        "\n",
        "# scale the data and select one, most important feature\n",
        "model = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    SelectKBest(f_classif, k=1),\n",
        "    SVC()\n",
        ")\n",
        "\n",
        "model = estimate_model(\n",
        "    X_train,\n",
        "    X_test,\n",
        "    y_train,\n",
        "    y_test,\n",
        "    model=model\n",
        ")"
      ],
      "metadata": {
        "id": "8Eibt5aMiQVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check what feature was selected"
      ],
      "metadata": {
        "id": "tGfPsAEakQ7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extract feature selection step from the pipeline\n",
        "f_selection_step = model[-2]\n",
        "\n",
        "# extract the number of the feature that was selected\n",
        "print(f_selection_step.get_feature_names_out())"
      ],
      "metadata": {
        "id": "aFyCxIPmi6VG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "- extract the mean power of alpha from the FC3, FCz, FC4, C3, Cz, and C4 channels from time window of 0 - 1 s.\n",
        "- extract the mean amplitude in time window 0 - 1 s from the FC3, FCz, FC4, C3, Cz, and C4 channels.\n",
        "- select 10 percentile of best features. Use [`SelectPercentile`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectPercentile.html)."
      ],
      "metadata": {
        "id": "FYQqoW_rHTUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "picks = ['FC3', 'FCz', 'FC4','C3', 'Cz', 'C4']\n",
        "\n",
        "# create X and y datasets\n",
        "epochs = all_epochs.copy()\n",
        "\n",
        "y = epochs.events[:, -1] - 1\n",
        "\n",
        "# create X and y datasets\n",
        "epochs = all_epochs.copy()\n",
        "\n",
        "y = epochs.events[:, -1] - 1\n",
        "\n",
        "# specral features\n",
        "# your code here\n",
        "# X_spectrum =\n",
        "\n",
        "# time-domain features\n",
        "# your code here\n",
        "# X_time =\n",
        "\n",
        "# concatenate features and reshape X to (n_samples, n_features) shape\n",
        "# use np.concatenate()\n",
        "# X =\n",
        "\n",
        "print(f\"Shape of y set (labels): {y.shape}\\nShape of X set (features): {X.shape}\")"
      ],
      "metadata": {
        "id": "4lBxC8nUHTUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit and predict\n",
        "X_train = X[:-135]\n",
        "X_test = X[-135:]\n",
        "y_train = y[:-135]\n",
        "y_test = y[-135:]\n",
        "\n",
        "# scale the data and select 10 percentile of most important feature\n",
        "# model = make_pipeline(\n",
        "  # TODO\n",
        "#)\n",
        "\n",
        "model = estimate_model(\n",
        "    X_train,\n",
        "    X_test,\n",
        "    y_train,\n",
        "    y_test,\n",
        "    model=model\n",
        ")"
      ],
      "metadata": {
        "id": "Jxos8FFGHTUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check what feature was selected"
      ],
      "metadata": {
        "id": "w4c_hBp5HTUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extract feature selection step from the pipeline\n",
        "f_selection_step = model[-2]\n",
        "\n",
        "# extract the number of the feature that was selected\n",
        "print(f_selection_step.get_feature_names_out())"
      ],
      "metadata": {
        "id": "7LxpSKlGHTUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "- extract the mean power of alpha from the FC3, FCz, FC4, C3, Cz, and C4 channels from time window of 0 - 1 s.\n",
        "- extract the mean amplitude in time window 0 - 1 s from the FC3, FCz, FC4, C3, Cz, and C4 channels.\n",
        "- use wrapper feature selection method: [`SequentialFeatureSelector`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SequentialFeatureSelector.html). Keep in mind that `SequentialFeatureSelector` is parametrized with the estimator."
      ],
      "metadata": {
        "id": "hOWg7-vPkJve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "picks = ['FC3', 'FCz', 'FC4','C3', 'Cz', 'C4']\n",
        "\n",
        "# create X and y datasets\n",
        "epochs = all_epochs.copy()\n",
        "\n",
        "y = epochs.events[:, -1] - 1\n",
        "\n",
        "# create X and y datasets\n",
        "epochs = all_epochs.copy()\n",
        "\n",
        "y = epochs.events[:, -1] - 1\n",
        "\n",
        "# specral features\n",
        "# your code here\n",
        "# X_spectrum =\n",
        "\n",
        "# time-domain features\n",
        "# your code here\n",
        "# X_time =\n",
        "\n",
        "# concatenate features and reshape X to (n_samples, n_features) shape\n",
        "# use np.concatenate()\n",
        "# X =\n",
        "\n",
        "print(f\"Shape of y set (labels): {y.shape}\\nShape of X set (features): {X.shape}\")"
      ],
      "metadata": {
        "id": "d9VY7_mYkJve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit and predict\n",
        "X_train = X[:-135]\n",
        "X_test = X[-135:]\n",
        "y_train = y[:-135]\n",
        "y_test = y[-135:]\n",
        "\n",
        "# scale the data and perform sequential feature selection\n",
        "# model = make_pipeline(\n",
        "#    TODO\n",
        "# )\n",
        "\n",
        "model = estimate_model(\n",
        "    X_train,\n",
        "    X_test,\n",
        "    y_train,\n",
        "    y_test,\n",
        "    model=model\n",
        ")"
      ],
      "metadata": {
        "id": "dW50nI87kJvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check what feature was selected"
      ],
      "metadata": {
        "id": "c6sKMTeJltrJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extract feature selection step from the pipeline\n",
        "f_selection_step = model[-2]\n",
        "\n",
        "# extract the number of the feature that was selected\n",
        "print(f_selection_step.get_feature_names_out())"
      ],
      "metadata": {
        "id": "rmUehtCQltrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Signal-based features"
      ],
      "metadata": {
        "id": "JaUWb2cclzA-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1 Extract signal on FC3 channel and calculate mean, max, min and std of the signal"
      ],
      "metadata": {
        "id": "R_G9ZV1Ql-4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create X and y datasets\n",
        "epochs = all_epochs.copy()\n",
        "\n",
        "y = epochs.events[:, -1] - 1\n",
        "\n",
        "picks = ['FC3']\n",
        "X_data = epochs.get_data(tmin=0, tmax=1, picks=picks, copy=True)\n",
        "\n",
        "# extract features\n",
        "X_mean = np.mean(X_data, axis=-1)\n",
        "X_max = # TODO\n",
        "X_min = # TODO\n",
        "X_std = # TODO\n",
        "\n",
        "# concatenate features and reshape X to (n_samples, n_features) shape\n",
        "X = np.concatenate((X_mean, X_max, X_min, X_std), axis=1).reshape(len(epochs), -1)\n",
        "\n",
        "print(f\"Shape of y set (labels): {y.shape}\\nShape of X set (features): {X.shape}\")"
      ],
      "metadata": {
        "id": "BoRMIPwrl-47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit and predict\n",
        "X_train = X[:-135]\n",
        "X_test = X[-135:]\n",
        "y_train = y[:-135]\n",
        "y_test = y[-135:]\n",
        "\n",
        "_ = estimate_model(\n",
        "    X_train,\n",
        "    X_test,\n",
        "    y_train,\n",
        "    y_test,\n",
        ")"
      ],
      "metadata": {
        "id": "0xYOG2a8l-48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2 Extract signals from the FC3, FC4, C3, and C4 channels. Calculate the mean, maximum, minimum, and standard deviation of the signals. Finally, perform feature selection using a method of your choice."
      ],
      "metadata": {
        "id": "_5oUs1d0IaiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create X and y datasets\n",
        "epochs = all_epochs.copy()\n",
        "\n",
        "y = epochs.events[:, -1] - 1\n",
        "\n",
        "# extract features\n",
        "# picks =\n",
        "# X =\n",
        "\n",
        "print(f\"Shape of y set (labels): {y.shape}\\nShape of X set (features): {X.shape}\")"
      ],
      "metadata": {
        "id": "_lwjaa8UIaiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit and predict\n",
        "X_train = X[:-135]\n",
        "X_test = X[-135:]\n",
        "y_train = y[:-135]\n",
        "y_test = y[-135:]\n",
        "\n",
        "# model = make_pipeline(\n",
        "#    TODO\n",
        "# )\n",
        "\n",
        "_ = estimate_model(\n",
        "    X_train,\n",
        "    X_test,\n",
        "    y_train,\n",
        "    y_test,\n",
        "    model = model\n",
        ")"
      ],
      "metadata": {
        "id": "uNP3dqGiIaiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.3 Extract signal on C3 channel and calculate [`catch22`](https://time-series-features.gitbook.io/catch22-features) features"
      ],
      "metadata": {
        "id": "ec4z9-Wjmhbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycatch22"
      ],
      "metadata": {
        "id": "6MFUnWoFmoJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pycatch22"
      ],
      "metadata": {
        "id": "vtuJUd_4mhby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create y dataset\n",
        "epochs = all_epochs.copy()\n",
        "y = epochs.events[:, -1] - 1"
      ],
      "metadata": {
        "id": "hlo8C9heoV_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create X dataset: **for each trial/epoch calculate catch22 features.**\n",
        "\n",
        "Note, that `pycatch22.catch22_all()` returns dict with two keys: `names` and `values`. Names are names of the features, and values are values of features. E.g.:\n",
        "\n",
        "```\n",
        "X = [1,2,3,4,5,6,7]\n",
        "features = pycatch22.catch22_all(X)['values']\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xgceOIgHom3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create X dataset: for each trial/epoch calculate catch22 features\n",
        "\n",
        "# extract data\n",
        "picks = ['C3']\n",
        "X_data = epochs.get_data(tmin=0, tmax=1, picks=picks, copy=True)\n",
        "\n",
        "# extract features\n",
        "# X =\n",
        "\n",
        "# concatenate features and reshape X to (n_samples, n_features) shape\n",
        "X = X.reshape(len(epochs), -1)\n",
        "\n",
        "print(f\"Shape of y set (labels): {y.shape}\\nShape of X set (features): {X.shape}\")"
      ],
      "metadata": {
        "id": "P6dD5cLcoZ7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit and predict\n",
        "X_train = X[:-135]\n",
        "X_test = X[-135:]\n",
        "y_train = y[:-135]\n",
        "y_test = y[-135:]\n",
        "\n",
        "_ = estimate_model(\n",
        "    X_train,\n",
        "    X_test,\n",
        "    y_train,\n",
        "    y_test,\n",
        ")"
      ],
      "metadata": {
        "id": "NVUiTGtRmhby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.4 Extract signal on C3 channel and calculate [`catch22`](https://time-series-features.gitbook.io/catch22-features) features and perform feature selection"
      ],
      "metadata": {
        "id": "ISd5Y9hTpbSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create y dataset\n",
        "epochs = all_epochs.copy()\n",
        "y = epochs.events[:, -1] - 1"
      ],
      "metadata": {
        "id": "hbWksLcspWpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create X dataset: for each trial/epoch calculate catch22 features\n",
        "\n",
        "# extract data\n",
        "picks = ['C3']\n",
        "X_data = epochs.get_data(tmin=0, tmax=1, picks=picks, copy=True)\n",
        "\n",
        "# extract features\n",
        "# X =\n",
        "\n",
        "# concatenate features and reshape X to (n_samples, n_features) shape\n",
        "X = X.reshape(len(epochs), -1)\n",
        "\n",
        "print(f\"Shape of y set (labels): {y.shape}\\nShape of X set (features): {X.shape}\")"
      ],
      "metadata": {
        "id": "z9WL-a9spWpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit and predict\n",
        "X_train = X[:-135]\n",
        "X_test = X[-135:]\n",
        "y_train = y[:-135]\n",
        "y_test = y[-135:]\n",
        "\n",
        "# model = make_pipeline(\n",
        "#   TODO\n",
        "# )\n",
        "\n",
        "_ = estimate_model(\n",
        "    X_train,\n",
        "    X_test,\n",
        "    y_train,\n",
        "    y_test,\n",
        "    model=model\n",
        ")"
      ],
      "metadata": {
        "id": "RgqVquAWpWpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check what feature(s) were selected"
      ],
      "metadata": {
        "id": "6Wz-c0P8psQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extract feature selection step from the pipeline\n",
        "f_selection_step = model[-2]\n",
        "\n",
        "# extract the number of the feature that was selected\n",
        "print(f_selection_step.get_feature_names_out())"
      ],
      "metadata": {
        "id": "XJX_OwJ_psQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.5 Extract signal on C3 channel and calculate features from [`tsfresh`](https://tsfresh.readthedocs.io/en/latest/text/quick_start.html).\n",
        "\n",
        "**This example is solved.You can now explore tsfresh features on your own.**"
      ],
      "metadata": {
        "id": "2tidLiyTp6Nz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tsfresh"
      ],
      "metadata": {
        "id": "bOhhmuQ0p616"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tsfresh import extract_features\n",
        "from tsfresh.utilities.dataframe_functions import impute"
      ],
      "metadata": {
        "id": "7HBbGnYwp7bG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create y dataset\n",
        "epochs = all_epochs.copy()\n",
        "y = epochs.events[:, -1] - 1"
      ],
      "metadata": {
        "id": "EjajqldNqlwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract data\n",
        "picks = ['C3']\n",
        "epochs_cropped = epochs.copy().crop(tmin=0, tmax=1).pick(picks)\n",
        "\n",
        "# extract data to df. This format is requires by tsfresh, see documentation\n",
        "epochs_cropped_df = epochs_cropped.to_data_frame().drop(columns='condition')\n",
        "\n",
        "# extract features\n",
        "X_df = extract_features(\n",
        "    epochs_cropped_df,\n",
        "    column_id='epoch',\n",
        "    column_sort='time',\n",
        "    impute_function=impute\n",
        "    )\n",
        "\n",
        "# reshape X to (n_samples, n_features) shape\n",
        "X = X_df.to_numpy().reshape(len(epochs), -1)\n",
        "\n",
        "print(f\"Shape of y set (labels): {y.shape}\\nShape of X set (features): {X.shape}\")"
      ],
      "metadata": {
        "id": "k4RSbJszqlw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2-EOEe-gxS9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit and predict\n",
        "X_train = X[:-135]\n",
        "X_test = X[-135:]\n",
        "y_train = y[:-135]\n",
        "y_test = y[-135:]\n",
        "\n",
        "# scale the data and select one, most important feature\n",
        "model = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    SelectKBest(f_classif, k=1),\n",
        "    SVC()\n",
        ")\n",
        "\n",
        "model = estimate_model(\n",
        "    X_train,\n",
        "    X_test,\n",
        "    y_train,\n",
        "    y_test,\n",
        "    model=model\n",
        ")"
      ],
      "metadata": {
        "id": "2qufJM6FqcWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check what feature was selected"
      ],
      "metadata": {
        "id": "ufRIqqL-KZKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extract feature selection step from the pipeline\n",
        "f_selection_step = model[-2]\n",
        "\n",
        "# extract the number of the feature that was selected\n",
        "print(f_selection_step.get_feature_names_out())"
      ],
      "metadata": {
        "id": "lJytIwXzKZKh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}